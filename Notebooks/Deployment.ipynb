{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 8818691,
          "sourceType": "datasetVersion",
          "datasetId": 5278766
        },
        {
          "sourceId": 8818793,
          "sourceType": "datasetVersion",
          "datasetId": 5305265
        }
      ],
      "dockerImageVersionId": 30732,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install llmsherpa langchain chromadb\n",
        "!apt-get install git-lfs\n",
        "!git lfs install\n",
        "!pip install gradio\n",
        "!git config --global credential.helper 'cache --timeout=3600'\n",
        "!echo \"machine huggingface.co login user password $token\" > ~/.netrc\n",
        "%pip install chromadb\n",
        "%pip install sentence-transformers\n",
        "pip install -U langchain-community\n",
        "pip install rarfile\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T13:36:51.178509Z",
          "iopub.execute_input": "2024-07-21T13:36:51.178748Z",
          "iopub.status.idle": "2024-07-21T13:37:40.903225Z",
          "shell.execute_reply.started": "2024-07-21T13:36:51.178726Z",
          "shell.execute_reply": "2024-07-21T13:37:40.902073Z"
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "collapsed": true,
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ORnjoGNkFgR",
        "outputId": "057ae4aa-9f56-49e4-c598-5218e03778b1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llmsherpa\n",
            "  Downloading llmsherpa-0.1.4-py3-none-any.whl (13 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.10-py3-none-any.whl (990 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.0/990.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chromadb\n",
            "  Downloading chromadb-0.5.4-py3-none-any.whl (581 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.4/581.4 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from llmsherpa) (2.0.7)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.22 (from langchain)\n",
            "  Downloading langchain_core-0.2.22-py3-none-any.whl (373 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.5/373.5 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.93-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
            "Collecting chroma-hnswlib==0.7.5 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.111.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.30.3-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.4)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.3)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.9.12 (from chromadb)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.27.0 (from chromadb)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (3.1.4)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting email_validator>=2.0.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx>=0.27.0->chromadb)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.27.0->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.22->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.0)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<=7.1,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.23.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (13.7.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb) (2.1.5)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.22->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=44157e795dda48970fca4bdf8565244aa70fde02b9a97992b18a4e6cea9489be\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, python-multipart, python-dotenv, overrides, orjson, opentelemetry-util-http, opentelemetry-proto, llmsherpa, jsonpointer, importlib-metadata, humanfriendly, httptools, h11, dnspython, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, jsonpatch, httpcore, email_validator, coloredlogs, opentelemetry-semantic-conventions, opentelemetry-instrumentation, onnxruntime, langsmith, kubernetes, httpx, opentelemetry-sdk, opentelemetry-instrumentation-asgi, langchain-core, fastapi-cli, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, fastapi, langchain, chromadb\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.0.0\n",
            "    Uninstalling importlib_metadata-8.0.0:\n",
            "      Successfully uninstalled importlib_metadata-8.0.0\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.3 chroma-hnswlib-0.7.5 chromadb-0.5.4 coloredlogs-15.0.1 deprecated-1.2.14 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.1 fastapi-cli-0.0.4 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 humanfriendly-10.0 importlib-metadata-7.1.0 jsonpatch-1.33 jsonpointer-3.0.0 kubernetes-30.1.0 langchain-0.2.10 langchain-core-0.2.22 langchain-text-splitters-0.2.2 langsmith-0.1.93 llmsherpa-0.1.4 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.18.1 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opentelemetry-util-http-0.46b0 orjson-3.10.6 overrides-7.7.0 posthog-3.5.0 pypika-0.48.9 python-dotenv-1.0.1 python-multipart-0.0.9 starlette-0.37.2 uvicorn-0.30.3 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Git LFS initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rarfile\n",
        "import os\n",
        "\n",
        "# Chemin du fichier RAR\n",
        "rar_path = '/content/sample_data/VS/Chroma VS.rar'\n",
        "\n",
        "# Chemin du répertoire de destination\n",
        "dest_path = '/content/sample_data/VS'\n",
        "\n",
        "# Vérifiez si le répertoire de destination existe, sinon créez-le\n",
        "if not os.path.exists(dest_path):\n",
        "    os.makedirs(dest_path)\n",
        "\n",
        "# Ouvrez le fichier RAR\n",
        "with rarfile.RarFile(rar_path) as rf:\n",
        "    # Extrayez tous les fichiers dans le répertoire de destination\n",
        "    rf.extractall(path=dest_path)\n",
        "\n",
        "print(f'Extraction terminée. Les fichiers sont extraits dans {dest_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL9Ij8cflEFj",
        "outputId": "4ee01525-bfbb-44aa-f915-a9c3b48903b5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction terminée. Les fichiers sont extraits dans /content/sample_data/VS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "emb_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=emb_model,\n",
        "    cache_folder=os.getenv('SENTENCE_TRANSFORMERS_HOME')\n",
        ")\n",
        "# The vectorstore to use to index the summaries\n",
        "vectorstore = Chroma(\n",
        "    collection_name=\"mm_rag_mistral\",\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=\"FiscaBOT_vector_store\",\n",
        ")\n",
        "\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "import uuid\n",
        "from langchain.schema.document import Document\n",
        "\n",
        " # Initialize the storage layer\n",
        "store = InMemoryStore()\n",
        "id_key = \"doc_id\"\n",
        "\n",
        "retriever = MultiVectorRetriever(\n",
        "        vectorstore=vectorstore,\n",
        "        docstore=store,\n",
        "        id_key=id_key\n",
        "    )\n",
        "\n",
        "\n",
        "def add_documents(retriever, doc_contents, filename, document_type):\n",
        "    doc_ids = [str(uuid.uuid4()) for _ in doc_contents]\n",
        "    child_text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000)\n",
        "    sub_docs = []\n",
        "\n",
        "    # Assuming the first two contents are company name and sector\n",
        "    # company_name = doc_contents[0] if len(doc_contents) > 0 else \"Unknown\"\n",
        "    # activity_sector = doc_contents[1] if len(doc_contents) > 1 else \"Unknown\"\n",
        "    # document_context = f\"Company: {company_name}, Sector: {activity_sector}\"\n",
        "\n",
        "    for i, doc in enumerate(doc_contents):\n",
        "        _id = doc_ids[i]\n",
        "        _sub_docs = child_text_splitter.create_documents([doc])\n",
        "        for _doc in _sub_docs:\n",
        "            _doc.metadata['doc_id'] = _id\n",
        "            _doc.metadata['pdf_name'] = filename\n",
        "#             _doc.metadata['year'] = year\n",
        "            _doc.metadata['document_type'] = document_type\n",
        "            # _doc.metadata['document_context'] = document_context  # New metadata field\n",
        "\n",
        "        sub_docs.extend(_sub_docs)\n",
        "\n",
        "    retriever.vectorstore.add_documents(sub_docs)\n",
        "    retriever.docstore.mset(list(zip(doc_ids, doc_contents)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T13:39:29.296953Z",
          "iopub.execute_input": "2024-07-21T13:39:29.297665Z",
          "iopub.status.idle": "2024-07-21T13:40:04.459079Z",
          "shell.execute_reply.started": "2024-07-21T13:39:29.297620Z",
          "shell.execute_reply": "2024-07-21T13:40:04.458292Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "7044f9e3432e46fda88a116d14a0f96c",
            "019c9960786149488b9a5d3b92d8a8a0",
            "46a3849039e0411893105b4084a48793",
            "a15608884dc64b2b882a2877c57d7282",
            "40781bab3b114029a9404e3910362a40",
            "bfee4f5fb3724e508cd2132a465f2384",
            "31d77207b137441eb79209486a76376d",
            "57acc90fe5654c5fb7858e3eb820068f",
            "0b996f655acc450da61b67d23c7e532a",
            "4dc931407814484ebc366022a4db3aaf",
            "bdd68b99d9e042839012c96f22f5f10f"
          ]
        },
        "id": "F-75mLUgkFgd",
        "outputId": "3c02b529-6001-4811-97bd-e449f0f70569"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n  warn_deprecated(\n/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm, trange\n2024-07-21 13:39:44.646435: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-21 13:39:44.646550: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-21 13:39:44.870999: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7044f9e3432e46fda88a116d14a0f96c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "019c9960786149488b9a5d3b92d8a8a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46a3849039e0411893105b4084a48793"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a15608884dc64b2b882a2877c57d7282"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40781bab3b114029a9404e3910362a40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfee4f5fb3724e508cd2132a465f2384"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31d77207b137441eb79209486a76376d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57acc90fe5654c5fb7858e3eb820068f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b996f655acc450da61b67d23c7e532a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4dc931407814484ebc366022a4db3aaf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdd68b99d9e042839012c96f22f5f10f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llmsherpa.readers import LayoutPDFReader\n",
        "\n",
        "llmsherpa_api_url = \"https://readers.llmsherpa.com/api/document/developer/parseDocument?renderFormat=all\"\n",
        "pdf_reader = LayoutPDFReader(llmsherpa_api_url)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T13:40:04.460356Z",
          "iopub.execute_input": "2024-07-21T13:40:04.461456Z",
          "iopub.status.idle": "2024-07-21T13:40:04.467969Z",
          "shell.execute_reply.started": "2024-07-21T13:40:04.461417Z",
          "shell.execute_reply": "2024-07-21T13:40:04.467057Z"
        },
        "trusted": true,
        "id": "LIxws9YokFge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorize elements by type\n",
        "def categorize_elements(doc):\n",
        "    \"\"\"\n",
        "    Categorize extracted elements from a PDF into  texts.\n",
        "    \"\"\"\n",
        "    texts=[]\n",
        "\n",
        "    for chunk in doc.chunks():\n",
        "      texts.append(str(chunk.to_context_text()))\n",
        "\n",
        "    return texts"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T13:40:04.469655Z",
          "iopub.execute_input": "2024-07-21T13:40:04.469970Z",
          "iopub.status.idle": "2024-07-21T13:40:04.487525Z",
          "shell.execute_reply.started": "2024-07-21T13:40:04.469947Z",
          "shell.execute_reply": "2024-07-21T13:40:04.486643Z"
        },
        "trusted": true,
        "id": "02vhdEVykFgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import concurrent.futures\n",
        "\n",
        "def process_pdf(folder_path, filename):\n",
        "    pdf_path = os.path.join(folder_path, filename)\n",
        "    doc = pdf_reader.read_pdf(pdf_path)  # Assuming 'read_pdf' is the correct method\n",
        "\n",
        "    # Obtenir le nom du dossier parent comme type de document\n",
        "    document_type = os.path.basename(os.path.dirname(pdf_path))\n",
        "\n",
        "    add_documents(retriever, categorize_elements(doc), filename, document_type)\n",
        "    return f\"Processed {filename}\"\n",
        "\n",
        "def main(root_folder):\n",
        "    # Créer un ThreadPoolExecutor\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        futures = []\n",
        "        # Parcourir récursivement tous les répertoires\n",
        "        for folder_path, _, filenames in os.walk(root_folder):\n",
        "            for filename in filenames:\n",
        "                if filename.endswith(\".pdf\"):\n",
        "                    # Soumettre des tâches à l'executor\n",
        "                    future = executor.submit(process_pdf, folder_path, filename)\n",
        "                    futures.append(future)\n",
        "\n",
        "        # Gérer les résultats dès qu'ils sont disponibles\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            try:\n",
        "                print(future.result())\n",
        "            except Exception as e:\n",
        "                print(f\"Une erreur s'est produite : {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(\"/kaggle/input/datasetpdf-fiscabot\")\n",
        "    vectorstore.persist()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T13:40:04.488930Z",
          "iopub.execute_input": "2024-07-21T13:40:04.489655Z",
          "iopub.status.idle": "2024-07-21T13:43:59.859138Z",
          "shell.execute_reply.started": "2024-07-21T13:40:04.489626Z",
          "shell.execute_reply": "2024-07-21T13:43:59.857480Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "5mNR9-B0kFgf",
        "outputId": "30c27b26-0a6d-4a9b-b6f1-e80c310eee83"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 27\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(root_folder)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Gérer les résultats dès qu'ils sont disponibles\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(futures):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:245\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    243\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 245\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUne erreur s\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mest produite : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 34\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/datasetpdf-fiscabot\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     vectorstore\u001b[38;5;241m.\u001b[39mpersist()\n",
            "Cell \u001b[0;32mIn[10], line 16\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(root_folder)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(root_folder):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Créer un ThreadPoolExecutor\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     17\u001b[0m         futures \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# Parcourir récursivement tous les répertoires\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:649\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ],
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r FiscaBOT_vector_store.zip FiscaBOT_vector_store"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T13:43:59.860118Z",
          "iopub.status.idle": "2024-07-21T13:43:59.860784Z",
          "shell.execute_reply.started": "2024-07-21T13:43:59.860538Z",
          "shell.execute_reply": "2024-07-21T13:43:59.860559Z"
        },
        "trusted": true,
        "id": "nuDT1Ir3kFgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] ='PUT YOUR TOKEN HERE'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T13:46:08.676703Z",
          "iopub.execute_input": "2024-07-21T13:46:08.677335Z",
          "iopub.status.idle": "2024-07-21T13:46:08.688941Z",
          "shell.execute_reply.started": "2024-07-21T13:46:08.677288Z",
          "shell.execute_reply": "2024-07-21T13:46:08.688015Z"
        },
        "trusted": true,
        "id": "WhvyhtBJkFgh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Specify the path to the zip file\n",
        "zip_file_path = 'FiscaBOT_vector_store'\n",
        "\n",
        "# Get the size of the zip file\n",
        "zip_file_size = os.path.getsize(zip_file_path)\n",
        "\n",
        "# Convert size to human-readable format\n",
        "def convert_bytes(size):\n",
        "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
        "        if size < 1024.0:\n",
        "            return \"%3.1f %s\" % (size, x)\n",
        "        size /= 1024.0\n",
        "\n",
        "# Print the size of the zip file\n",
        "print(\"Size of the zip file:\", convert_bytes(zip_file_size))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T13:44:43.569595Z",
          "iopub.execute_input": "2024-07-21T13:44:43.569883Z",
          "iopub.status.idle": "2024-07-21T13:44:43.576835Z",
          "shell.execute_reply.started": "2024-07-21T13:44:43.569856Z",
          "shell.execute_reply": "2024-07-21T13:44:43.575453Z"
        },
        "trusted": true,
        "id": "oMjmYCTskFgi",
        "outputId": "6866ece0-8160-4f7c-e7ea-8a5d266bbde5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Size of the zip file: 4.0 KB\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from huggingface_hub import InferenceClient\n",
        "import os\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load tokenizer and models\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"kimou605/shadow-clown-BioMistral-7B-DARE\")\n",
        "    print('success loading tokenizer')\n",
        "except Exception as e:\n",
        "    print(f'Error loading tokenizer: {e}')\n",
        "\n",
        "emb_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "try:\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=emb_model,\n",
        "        cache_folder=os.getenv('SENTENCE_TRANSFORMERS_HOME')\n",
        "    )\n",
        "    print('success build embedding model')\n",
        "except Exception as e:\n",
        "    print(f'Error building embedding model: {e}')\n",
        "\n",
        "try:\n",
        "    vectorstore = Chroma(\n",
        "        collection_name=\"mm_rag_mistral\",\n",
        "        embedding_function=embeddings,\n",
        "        persist_directory=\"/content/sample_data/VS/Chroma VS\",\n",
        "    )\n",
        "    print('success loading vector store')\n",
        "except Exception as e:\n",
        "    print(f'Error loading vector store: {e}')\n",
        "\n",
        "try:\n",
        "    client = InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.1', token = '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')\n",
        "    print('success loading inference client')\n",
        "except Exception as e:\n",
        "    print(f'Error loading inference client: {e}')\n",
        "\n",
        "def respond(\n",
        "    message,\n",
        "    history: list[tuple[str, str]],\n",
        "    system_message,\n",
        "    max_tokens,\n",
        "    temperature,\n",
        "    top_p,\n",
        "    context_history: list\n",
        "):\n",
        "    # Initialize or retrieve the session-specific context history\n",
        "    if context_history is None:\n",
        "        context_history = []\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
        "    for val in history:\n",
        "        if val[0]:\n",
        "            messages.append({\"role\": \"user\", \"content\": val[0]})\n",
        "        if val[1]:\n",
        "            messages.append({\"role\": \"assistant\", \"content\": val[1]})\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    try:\n",
        "        template = f\"<s>[INST] Provide a better search query for web search engine to answer the given question. Question: {message} [/INST]\"\n",
        "        rewritten_question = client.text_generation(\n",
        "            template,\n",
        "            max_new_tokens=248,\n",
        "            do_sample=True,\n",
        "            temperature=0.1,\n",
        "            top_p=0.95,\n",
        "            top_k=50,\n",
        "            repetition_penalty=1.1\n",
        "        )\n",
        "    except Exception as e:\n",
        "        yield f\"Error generating rewritten question: {e}\"\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        context = vectorstore.similarity_search_with_score(rewritten_question, 10)\n",
        "    except Exception as e:\n",
        "        yield f\"Error searching vector store: {e}\"\n",
        "        return\n",
        "\n",
        "    results = []\n",
        "    pdf_links = []\n",
        "    for index, item in enumerate(context, start=1):\n",
        "        context_item = list(item)\n",
        "        if context_item[1] <= 1:\n",
        "            content_context = f\"Content: {context_item[0].page_content}\"\n",
        "            metadata = context_item[0].metadata\n",
        "            pdf_name = f\"PDF Name: {metadata.get('pdf_name', 'N/A')}\"\n",
        "            link = f\"<a href='content/sample_data/PDFs/{metadata.get('pdf_name', 'N/A')}' download class='pdf-bubble'>{metadata.get('pdf_name', 'N/A')}</a>\"\n",
        "            if link not in pdf_links:\n",
        "                pdf_links.append(link)\n",
        "            year = f\"Year: {metadata.get('year', 'N/A')}\"\n",
        "            document_type = f\"Document Type: {metadata.get('document_type', 'N/A')}\"\n",
        "            content_description = f\"Content: {content_context}\"\n",
        "            results.append(f\"Context {index}: {pdf_name}, {year}, {document_type}, {content_description}, {content_context}\")\n",
        "\n",
        "    current_context = \"\\n\".join(results) if results else \"\"\n",
        "    if current_context:\n",
        "        current_context = f\"Here is a current context list with metadata:\\n{current_context}\"\n",
        "        context_history.append(current_context)\n",
        "\n",
        "    if len(context_history) >= 3:\n",
        "        context_history_last_three = f\" Here are the last 3 contexts: {''.join(map(str, context_history[-3:]))}\"\n",
        "    elif context_history:\n",
        "        context_history_last_three = f\" Here are the last context(s): {''.join(map(str, context_history))}\"\n",
        "    else:\n",
        "        context_history_last_three = ''\n",
        "\n",
        "    try:\n",
        "        chat_history = tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "    except Exception as e:\n",
        "        yield f\"Error applying chat template: {e}\"\n",
        "        return\n",
        "\n",
        "    prompt = f\"\"\"<s>[INST]  Instruction: You are a highly accurate financial analyst from Ersnt & Young tasked with providing precise, data-driven answers in a conversational format. Each response should include detailed numerical analysis and references to specific documents. Maintain the professionalism and thoroughness expected in the financial sector. The current year is 2024. Respond in the language of the user's input.Only respond from the context provided. {context_history_last_three} {current_context} Here is the chat history: {chat_history} Here is the user's question: {message} [/INST]\"\"\"\n",
        "\n",
        "    partial_message = \"\"\n",
        "    try:\n",
        "        for token in client.text_generation(\n",
        "                prompt,\n",
        "                max_new_tokens=max_tokens,\n",
        "                do_sample=True,\n",
        "                temperature=temperature,\n",
        "                top_p=top_p,\n",
        "                top_k=50,\n",
        "                repetition_penalty=1.1):\n",
        "            partial_message += token\n",
        "\n",
        "            if not pdf_links:\n",
        "                yield partial_message\n",
        "            else:\n",
        "                pdf_bubbles = ' '.join(pdf_links)\n",
        "                final_response = partial_message + \"<br>\" + pdf_bubbles\n",
        "                yield final_response\n",
        "    except Exception as e:\n",
        "        yield f\"Error generating response: {e}\"\n",
        "\n",
        "css = \"\"\"\n",
        "body, html {\n",
        "    height: 100%;\n",
        "    margin: 0;\n",
        "    background-color: #f0f0f0;\n",
        "    font-family: Arial, sans-serif;\n",
        "}\n",
        ".gradio-container {\n",
        "    display: flex;\n",
        "    flex-direction: column;\n",
        "    height: 100%;\n",
        "}\n",
        ".pdf-bubble {\n",
        "    display: inline-block;\n",
        "    background-color: #4CAF50; /* Green */\n",
        "    color: white;\n",
        "    padding: 5px 10px;\n",
        "    border-radius: 12px;\n",
        "    margin: 2px;\n",
        "    font-size: 12px;\n",
        "    line-height: 1.4;\n",
        "    text-decoration: none;\n",
        "}\n",
        ".pdf-bubble:hover {\n",
        "    background-color: #45a049; /* Darker green */\n",
        "}\n",
        "footer {\n",
        "    display: none !important;\n",
        "}\n",
        ".gr-button {\n",
        "    background-color: #4CAF50; /* Green */\n",
        "    color: white;\n",
        "    border: none;\n",
        "    padding: 10px 20px;\n",
        "    text-align: center;\n",
        "    text-decoration: none;\n",
        "    display: inline-block;\n",
        "    font-size: 16px;\n",
        "    margin: 4px 2px;\n",
        "    cursor: pointer;\n",
        "    border-radius: 16px;\n",
        "}\n",
        ".gr-button:hover {\n",
        "    background-color: #45a049; /* Darker green */\n",
        "}\n",
        ".gr-textbox, .gr-slider {\n",
        "    border: 2px solid #4CAF50; /* Green border */\n",
        "    border-radius: 4px;\n",
        "    padding: 10px;\n",
        "    margin-bottom: 10px;\n",
        "    width: 100%;\n",
        "}\n",
        ".gr-textbox input, .gr-slider input {\n",
        "    border: none;\n",
        "    outline: none;\n",
        "    width: 100%;\n",
        "    padding: 8px;\n",
        "}\n",
        ".gr-slider input[type=range] {\n",
        "    appearance: none;\n",
        "    width: 100%;\n",
        "    height: 8px;\n",
        "    background: #4CAF50; /* Green */\n",
        "    outline: none;\n",
        "    opacity: 0.7;\n",
        "    transition: opacity .2s;\n",
        "}\n",
        ".gr-slider input[type=range]:hover {\n",
        "    opacity: 1;\n",
        "}\n",
        ".gr-slider input[type=range]::-webkit-slider-thumb {\n",
        "    appearance: none;\n",
        "    width: 25px;\n",
        "    height: 25px;\n",
        "    background: #f44336; /* Red */\n",
        "    cursor: pointer;\n",
        "    border-radius: 50%;\n",
        "}\n",
        ".gr-slider input[type=range]::-moz-range-thumb {\n",
        "    width: 25px;\n",
        "    height: 25px;\n",
        "    background: #f44336; /* Red */\n",
        "    cursor: pointer;\n",
        "    border-radius: 50%;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "demo = gr.ChatInterface(\n",
        "    fn=respond,\n",
        "    additional_inputs=[\n",
        "        gr.Textbox(value=\"You are a friendly Chatbot.\", label=\"System message\"),\n",
        "        gr.Slider(minimum=1, maximum=2048, value=512, step=1, label=\"Max new tokens\"),\n",
        "        gr.Slider(minimum=0, maximum=1.0, value=0.7, step=0.1, label=\"Temperature\"),\n",
        "        gr.Slider(minimum=0.1, maximum=1.0, value=0.95, step=0.05, label=\"Top-p (nucleus sampling)\"),\n",
        "        gr.State([])  # Initialize a session-specific context history without label\n",
        "    ],\n",
        "    css=css,\n",
        "    # submit_btn=\"Submit\",  # Change the text of the submit button to \"Submit\"\n",
        "    # submit_button_style=\"background-color: #4CAF50; color: white; border-radius: 16px; padding: 10px 20px; border: none; cursor: pointer;\"  # Style the submit button\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.queue().launch(server_name=\"0.0.0.0\", server_port=7883)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T13:48:06.716786Z",
          "iopub.execute_input": "2024-07-21T13:48:06.717134Z",
          "iopub.status.idle": "2024-07-21T13:48:36.477261Z",
          "shell.execute_reply.started": "2024-07-21T13:48:06.717102Z",
          "shell.execute_reply": "2024-07-21T13:48:36.476452Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "cUojBg3IkFgj",
        "outputId": "00dbc15c-b697-49b4-d250-06f75b8ecaf1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "success loading tokenizer\n",
            "success build embedding model\n",
            "success loading vector store\n",
            "success loading inference client\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://8c47207d0effbc44cf.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8c47207d0effbc44cf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rarfile\n",
        "import os\n",
        "\n",
        "# Chemin du fichier RAR\n",
        "rar_path = '/content/PDF Data.rar'\n",
        "\n",
        "# Chemin du répertoire de destination\n",
        "dest_path = '/content/sample_data/PDFs'\n",
        "\n",
        "# Vérifiez si le répertoire de destination existe, sinon créez-le\n",
        "if not os.path.exists(dest_path):\n",
        "    os.makedirs(dest_path)\n",
        "\n",
        "# Ouvrez le fichier RAR\n",
        "with rarfile.RarFile(rar_path) as rf:\n",
        "    # Extrayez tous les fichiers dans le répertoire de destination\n",
        "    rf.extractall(path=dest_path)\n",
        "\n",
        "print(f'Extraction terminée. Les fichiers sont extraits dans {dest_path}')\n"
      ],
      "metadata": {
        "id": "b6UMM1qokFgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "179fb1a2-0e77-4861-c1d3-2e679935b223"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction terminée. Les fichiers sont extraits dans /content/sample_data/PDFs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rHN8cY5ykFgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_S-KtEWFkFgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "57kCS7oZkFgl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}